'ê³¼ì œ ë¶„ì„ ì—ì´ì „íŠ¸'
from typing import Dict, Any, List
import json
from pathlib import Path
import ast
import io
import sys
from contextlib import redirect_stdout
import re
import random
from .base_agent import BaseAgent
from anthropic import Anthropic
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv

class AssignmentAnalysisAgent(BaseAgent):
    def __init__(self):
        load_dotenv()
        api_key = os.getenv('ANTHROPIC_API_KEY')
        
        if not api_key:
            raise ValueError("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        api_key = api_key.strip().strip("'").strip('"').strip()
        self.anthropic = Anthropic(api_key=api_key)
        super().__init__()
        self.prompt_template = self.load_prompt('assignment_analysis_prompt.md')
        self.attempts_file = Path(__file__).parent / 'assignment_attempts.json'
        self.max_attempts = 3  # ë¬¸ì œë‹¹ ìµœëŒ€ ì‹œë„ íšŸìˆ˜
        self.cooldown_minutes = 30  # ì´ˆê³¼ ì‹œ ëŒ€ê¸° ì‹œê°„
        self.data_dir = Path(__file__).parent.parent / 'data' / 'topics'
        self.score_weights = {
            'concept': 0.3,
            'analysis': 0.3,
            'implementation': 0.4
        }
        self.attempt_penalties = {
            1: 1.0,  # ì²« ì‹œë„
            2: 0.9,  # ë‘ ë²ˆì§¸
            3: 0.8,  # ì„¸ ë²ˆì§¸
            4: 0.7   # ë„¤ ë²ˆì§¸ ì´ìƒ
        }
        self.thresholds = {
            'proceed': 80.0,
            'weak_point': 60.0,
            'critical': 40.0
        }
        # í”¼ë“œë°± ìŠ¤íƒ€ì¼ ì„¤ì •
        self.feedback_style = {
            "positive_reinforcement": True,
            "creativity_praise": True,
            "encouragement_messages": [
                "ë©‹ì§„ ì‹œë„ì˜ˆìš”! ğŸŒŸ",
                "ì°½ì˜ì ì¸ ì ‘ê·¼ì´ë„¤ìš”! âœ¨",
                "ìê¸°ë§Œì˜ ìŠ¤íƒ€ì¼ë¡œ ì˜ í‘œí˜„í–ˆì–´ìš”! ğŸ’«",
                "ì˜ˆì œì™€ ë‹¤ë¥´ì§€ë§Œ í›Œë¥­í•œ í•´ê²°ë°©ë²•ì´ì—ìš”! ğŸ¯",
                "ì½”ë“œê°€ ì˜ ì‘ë™í•˜ë„¤ìš”! ğŸ‘",
                "ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ìƒê°í•˜ë‹¤ë‹ˆ ëŒ€ë‹¨í•´ìš”! ğŸš€"
            ],
            "improvement_suggestions": [
                "ì¡°ê¸ˆ ë” ë°œì „ì‹œì¼œë³¼ê¹Œìš”? ğŸ’ª",
                "ì´ë ‡ê²Œ í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”? ğŸ’¡",
                "ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„ì „í•´ë³´ì„¸ìš”! ğŸ¯",
                "ìƒˆë¡œìš´ ì‹œë„ë¥¼ í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”? âœ¨"
            ]
        }

    def _check_attempt_limit(self, user_id: str, topic_id: str, assignment_id: int) -> Dict[str, Any]:
        """ì‚¬ìš©ìë³„ ê³¼ì œ ì œì¶œ íšŸìˆ˜ ì œí•œ í™•ì¸"""
        try:
            if not self.attempts_file.exists():
                return {'allowed': True, 'remaining_attempts': self.max_attempts}

            with open(self.attempts_file, 'r') as f:
                attempts = json.load(f)

            attempt_key = f"{user_id}_{topic_id}_{assignment_id}"
            user_attempts = attempts.get(attempt_key, {
                'attempts': 0,
                'last_attempt': None,
                'cooldown_until': None
            })

            now = datetime.now()

            # ì¿¨ë‹¤ìš´ ì‹œê°„ í™•ì¸
            if user_attempts.get('cooldown_until'):
                cooldown_until = datetime.fromisoformat(user_attempts['cooldown_until'])
                if now < cooldown_until:
                    remaining_minutes = int((cooldown_until - now).total_seconds() / 60)
                    return {
                        'allowed': False,
                        'error': f'ì œì¶œ íšŸìˆ˜ ì´ˆê³¼ë¡œ ì¸í•œ ëŒ€ê¸° ì‹œê°„ì´ {remaining_minutes}ë¶„ ë‚¨ì•˜ìŠµë‹ˆë‹¤.'
                    }

            # ì¿¨ë‹¤ìš´ì´ ëë‚¬ê±°ë‚˜ ì—†ìœ¼ë©´ ì‹œë„ íšŸìˆ˜ ì´ˆê¸°í™”
            if user_attempts.get('cooldown_until'):
                cooldown_until = datetime.fromisoformat(user_attempts['cooldown_until'])
                if now >= cooldown_until:
                    user_attempts = {
                        'attempts': 0,
                        'last_attempt': None,
                        'cooldown_until': None
                    }

            remaining_attempts = self.max_attempts - user_attempts['attempts']
            return {'allowed': remaining_attempts > 0, 'remaining_attempts': remaining_attempts}

        except Exception as e:
            print(f"ì œì¶œ íšŸìˆ˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {'allowed': True, 'remaining_attempts': self.max_attempts}

    def _update_attempt_count(self, user_id: str, topic_id: str, assignment_id: int):
        """ì‚¬ìš©ìë³„ ê³¼ì œ ì œì¶œ íšŸìˆ˜ ì—…ë°ì´íŠ¸"""
        try:
            attempts = {}
            if self.attempts_file.exists():
                with open(self.attempts_file, 'r') as f:
                    attempts = json.load(f)

            attempt_key = f"{user_id}_{topic_id}_{assignment_id}"
            user_attempts = attempts.get(attempt_key, {
                'attempts': 0,
                'last_attempt': None,
                'cooldown_until': None
            })

            user_attempts['attempts'] += 1
            user_attempts['last_attempt'] = datetime.now().isoformat()

            # ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬ ì‹œ ì¿¨ë‹¤ìš´ ì‹œê°„ ì„¤ì •
            if user_attempts['attempts'] >= self.max_attempts:
                cooldown_until = datetime.now() + timedelta(minutes=self.cooldown_minutes)
                user_attempts['cooldown_until'] = cooldown_until.isoformat()

            attempts[attempt_key] = user_attempts

            with open(self.attempts_file, 'w') as f:
                json.dump(attempts, f, indent=2)

        except Exception as e:
            print(f"ì œì¶œ íšŸìˆ˜ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    async def analyze(self, assignment_type: str, answer: str, assignment_id: int, topic_id: str, user_id: str) -> Dict[str, Any]:
        """ê³¼ì œ ë‹µì•ˆ ë¶„ì„"""
        try:
            # íŒŒë¼ë¯¸í„° ê²€ì¦
            if not all([assignment_type, answer, assignment_id, topic_id, user_id]):
                missing_params = []
                if not assignment_type: missing_params.append('assignment_type')
                if not answer: missing_params.append('answer')
                if not assignment_id: missing_params.append('assignment_id')
                if not topic_id: missing_params.append('topic_id')
                if not user_id: missing_params.append('user_id')
                return {
                    'correct': False,
                    'message': f'í•„ìˆ˜ íŒŒë¼ë¯¸í„°ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {", ".join(missing_params)}'
                }

            # assignment_idë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
            try:
                assignment_id = int(assignment_id)
            except (TypeError, ValueError):
                return {
                    'correct': False,
                    'message': 'assignment_idëŠ” ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.'
                }

            # ì œì¶œ íšŸìˆ˜ ì œí•œ í™•ì¸
            attempt_check = self._check_attempt_limit(user_id, topic_id, assignment_id)
            if not attempt_check['allowed']:
                return {
                    'correct': False,
                    'message': attempt_check['error']
                }

            # ê³¼ì œ ë°ì´í„° ë¡œë“œ
            assignment_data = self._load_assignment_data(topic_id)
            assignment = next((a for a in assignment_data['assignments'] if a['id'] == assignment_id), None)
            
            if not assignment:
                return {'correct': False, 'message': 'ê³¼ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}

            # LLMì„ ì‚¬ìš©í•œ ë‹µì•ˆ ë¶„ì„
            analysis_result = await self._analyze_with_llm(assignment_type, answer, assignment)
            
            # ì œì¶œ íšŸìˆ˜ ì—…ë°ì´íŠ¸
            self._update_attempt_count(user_id, topic_id, assignment_id)
            
            # ë‚¨ì€ ì‹œë„ íšŸìˆ˜ ì¶”ê°€
            attempt_check = self._check_attempt_limit(user_id, topic_id, assignment_id)
            analysis_result['remaining_attempts'] = attempt_check.get('remaining_attempts', 0)
            
            return analysis_result

        except Exception as e:
            return {'correct': False, 'message': f'ì±„ì  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}

    async def _analyze_with_llm(self, assignment_type: str, answer: str, assignment: Dict) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•œ ë‹µì•ˆ ë¶„ì„"""
        try:
            if assignment_type in ['concept_basic', 'concept_application', 'concept_analysis', 'concept_debug', 'metaphor', 'theory_concept', 'concept_synthesis']:
                prompt = f"""# ê³¼ì œ ì •ë³´
ë¬¸ì œ ìœ í˜•: {assignment_type}
ë¬¸ì œ ë‚´ìš©: {assignment['content']}
ì œì¶œí•œ ë‹µì•ˆ: {answer}
ì •ë‹µ: {assignment['correct_answer']}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ë‹µì•ˆì´ ì •ë‹µì¸ê°€ìš”?
2. ë‹µì•ˆì— ëŒ€í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
3. í•™ìŠµìì˜ ì´í•´ë„ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.
4. ì¶”ê°€ í•™ìŠµì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì œì•ˆí•´ì£¼ì„¸ìš”."""

            elif assignment_type in ['implementation_playground', 'implementation_modify', 'implementation_creative']:
                test_cases_str = "\n".join([
                    f"ì…ë ¥: {tc['input']}, ì˜ˆìƒ ì¶œë ¥: {tc['output']}"
                    for tc in assignment['test_cases']
                ])
                
                prompt = f"""# ê³¼ì œ ì •ë³´
ë¬¸ì œ ìœ í˜•: {assignment_type}
ë¬¸ì œ ë‚´ìš©: {assignment['content']}
í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
{test_cases_str}

ì œì¶œí•œ ì½”ë“œ:
{answer}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì½”ë“œê°€ ë¬¸ì œì˜ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ë‚˜ìš”?
2. ì½”ë“œì˜ êµ¬í˜„ ë°©ì‹ê³¼ ìŠ¤íƒ€ì¼ì€ ì ì ˆí•œê°€ìš”?
3. ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ë¬´ì—‡ì¸ê°€ìš”?
4. í•™ìŠµìì˜ ì½”ë”© ìŠ¤í‚¬ ìˆ˜ì¤€ì„ í‰ê°€í•´ì£¼ì„¸ìš”."""

            response = await self.anthropic.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1024,
                messages=[{
                    "role": "user",
                    "content": prompt
                }]
            )

            # LLM ì‘ë‹µ íŒŒì‹±
            analysis = str(response.content)
            
            # ê°ê´€ì‹ ë¬¸ì œì˜ ê²½ìš° ì •ë‹µ ì—¬ë¶€ ì§ì ‘ ë¹„êµ
            if assignment_type in ['concept_basic', 'concept_application', 'concept_analysis', 'concept_debug', 'metaphor', 'theory_concept', 'concept_synthesis']:
                is_correct = answer == assignment['correct_answer']
            else:
                # êµ¬í˜„ ë¬¸ì œì˜ ê²½ìš° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰
                test_results = self._run_test_cases(answer, assignment['test_cases'])
                is_correct = all(result['passed'] for result in test_results)

            # ê¸ì •ì ì¸ í”¼ë“œë°± ì„ íƒ
            encouragement = random.choice(self.feedback_style['encouragement_messages'])
            improvement = random.choice(self.feedback_style['improvement_suggestions'])

            return {
                'correct': is_correct,
                'message': analysis,
                'feedback': f"{encouragement}\n\n{analysis}\n\n{improvement if not is_correct else ''}",
                'test_results': test_results if assignment_type in ['implementation_playground', 'implementation_modify', 'implementation_creative'] else None
            }

        except Exception as e:
            return {
                'correct': False,
                'message': f'ë‹µì•ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }

    def _load_assignment_data(self, topic_id: str) -> Dict[str, Any]:
        """ê³¼ì œ ë°ì´í„° ë¡œë“œ"""
        try:
            answer_file = self.data_dir / topic_id / 'content' / 'assignment_answers.json'
            if not answer_file.exists():
                raise FileNotFoundError(f'ê³¼ì œ ì •ë‹µ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {answer_file}')

            with open(answer_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            raise Exception(f'ê³¼ì œ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}')

    def _run_test_cases(self, code: str, test_cases: List[Dict]) -> List[Dict]:
        """êµ¬í˜„ ë¬¸ì œì˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰"""
        results = []
        
        # ì•ˆì „í•œ ì‹¤í–‰ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ ì„¤ì •
        globals_dict = {
            '__builtins__': {
                'print': print,
                'len': len,
                'range': range,
                'int': int,
                'str': str,
                'float': float,
                'list': list,
                'dict': dict,
                'set': set,
                'tuple': tuple,
                'sum': sum,
                'min': min,
                'max': max,
                'abs': abs,
                'round': round
            }
        }
        
        try:
            # ì½”ë“œ ì»´íŒŒì¼ ë° ì‹¤í–‰
            code_obj = compile(code, '<string>', 'exec')
            
            for test_case in test_cases:
                try:
                    # ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë§ˆë‹¤ ìƒˆë¡œìš´ ë¡œì»¬ ìŠ¤ì½”í”„ ìƒì„±
                    locals_dict = {}
                    
                    # ì…ë ¥ê°’ ì„¤ì •
                    if isinstance(test_case['input'], list):
                        for i, value in enumerate(test_case['input']):
                            locals_dict[f'input_{i+1}'] = value
                    else:
                        locals_dict['input_value'] = test_case['input']
                    
                    # ì¶œë ¥ ìº¡ì²˜ë¥¼ ìœ„í•œ StringIO ê°ì²´
                    output = io.StringIO()
                    
                    # ì½”ë“œ ì‹¤í–‰ ë° ì¶œë ¥ ìº¡ì²˜
                    with redirect_stdout(output):
                        exec(code_obj, globals_dict, locals_dict)
                    
                    # ì‹¤ì œ ì¶œë ¥ê°’ ê°€ì ¸ì˜¤ê¸°
                    actual_output = output.getvalue().strip()
                    
                    # ì˜ˆìƒ ì¶œë ¥ê°’ê³¼ ë¹„êµ
                    expected_output = str(test_case['output']).strip()
                    passed = actual_output == expected_output
                    
                    results.append({
                        'test_case': test_case,
                        'passed': passed,
                        'actual_output': actual_output,
                        'expected_output': expected_output
                    })
                    
                except Exception as e:
                    results.append({
                        'test_case': test_case,
                        'passed': False,
                        'error': str(e)
                    })
                    
        except SyntaxError as e:
            return [{
                'passed': False,
                'error': f'ì½”ë“œì— ë¬¸ë²• ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤: {str(e)}'
            }]
        except Exception as e:
            return [{
                'passed': False,
                'error': f'ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }]
            
        return results

    def _calculate_scores(self, questions):
        # ì ìˆ˜ ê³„ì‚° ë¡œì§
        pass

    def _identify_weak_points(self, scores):
        # ì·¨ì•½ì  ì‹ë³„ ë¡œì§
        pass

    def _generate_recommendations(self, scores):
        # ì¶”ì²œì‚¬í•­ ìƒì„± ë¡œì§
        pass

    def _calculate_total_score(self, scores):
        # ì¢…í•© ì ìˆ˜ ê³„ì‚° ë¡œì§
        pass

    def _calculate_achievement_rate(self, scores: list) -> float:
        """í•™ìŠµ ì„±ì·¨ë„ ê³„ì‚°"""
        if not scores:
            return 0.0
        return sum(scores) / len(scores)

    def check_criteria(self, achievement_rate: float) -> bool:
        """ê¸°ì¤€ íŒë³„"""
        return achievement_rate >= self.thresholds['proceed']

    def _analyze_code_quality(self, code: str) -> Dict[str, Any]:
        """ì½”ë“œ í’ˆì§ˆ ë¶„ì„"""
        try:
            quality_analysis = {
                'has_comments': bool(re.search(r'#.*', code)),
                'code_length': len(code.splitlines()),
                'creativity': bool(re.search(r'[^!]\s*[ğŸ˜ŠğŸŒŸâœ¨ğŸ’«ğŸ¯ğŸ‘‹]', code))  # ì°½ì˜ì  í‘œí˜„ í™•ì¸
            }
            return quality_analysis
        except Exception as e:
            print(f"ì½”ë“œ í’ˆì§ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}

    def _analyze_execution_result(self, code: str) -> Dict[str, Any]:
        """ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ ë¶„ì„"""
        try:
            # ì•ˆì „í•œ í™˜ê²½ì—ì„œ ì½”ë“œ ì‹¤í–‰
            local_vars = {}
            exec(code, {"__builtins__": {}}, local_vars)
            return {
                'success': True,
                'output': str(local_vars.get('__output__', 'ì‹¤í–‰ ê²°ê³¼ ì—†ìŒ'))
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def _generate_feedback(self, quality: Dict, exec_result: Dict) -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸ì •ì ì´ê³  ê²©ë ¤í•˜ëŠ” í”¼ë“œë°± ìƒì„±"""
        feedback = []
        
        # ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€ì— ë”°ë¥¸ ê¸°ë³¸ í”¼ë“œë°±
        if exec_result.get('success'):
            feedback.append(random.choice(self.feedback_style['encouragement_messages']))
            
            # ì°½ì˜ì„± ì¹­ì°¬
            if quality.get('creativity') and self.feedback_style['creativity_praise']:
                feedback.append("âœ¨ ìê¸°ë§Œì˜ ë…íŠ¹í•œ í‘œí˜„ì„ ë„£ì–´ì„œ ë”ìš± ë©‹ì§„ ì½”ë“œê°€ ë˜ì—ˆë„¤ìš”!")
        else:
            feedback.append(f"ğŸ’ª ê±°ì˜ ë‹¤ ì™”ì–´ìš”! ë‹¤ìŒ ë¶€ë¶„ë§Œ ìˆ˜ì •í•´ë³´ë©´ ë  ê²ƒ ê°™ì•„ìš”: {exec_result.get('error')}")

        # ì½”ë“œ í’ˆì§ˆì— ëŒ€í•œ ê¸ì •ì  í”¼ë“œë°±
        if quality.get('has_comments'):
            feedback.append("ğŸ“ ì£¼ì„ì„ ì˜ ì‘ì„±í•´ì£¼ì…¨ë„¤ìš”! ì½”ë“œë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì…¨ì–´ìš”.")
        else:
            feedback.append("ğŸ’¡ ì½”ë“œê°€ ì˜ ì‘ì„±ë˜ì—ˆì–´ìš”! ì£¼ì„ì„ ì¶”ê°€í•˜ë©´ ë” ë©‹ì§„ ì½”ë“œê°€ ë  ê²ƒ ê°™ì•„ìš”.")
        
        # ì½”ë“œ ê¸¸ì´ì— ë”°ë¥¸ í”¼ë“œë°±
        if quality.get('code_length', 0) > 5:
            feedback.append("ğŸš€ ì½”ë“œë¥¼ í™•ì¥í•´ì„œ ì‘ì„±í•˜ì…¨ë„¤ìš”! ìƒˆë¡œìš´ ì‹œë„ë¥¼ í•´ë³´ì‹œëŠ” ëª¨ìŠµì´ ë©‹ì ¸ìš”.")
        
        # ê°œì„  ì œì•ˆ
        if not exec_result.get('success') or not quality.get('has_comments'):
            feedback.append(random.choice(self.feedback_style['improvement_suggestions']))
        
        # ë§ˆë¬´ë¦¬ ê²©ë ¤ ë©”ì‹œì§€
        feedback.append("\nğŸ’« ê³„ì†í•´ì„œ ì´ë ‡ê²Œ ìì‹ ë§Œì˜ ë°©ì‹ìœ¼ë¡œ ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”! ì—¬ëŸ¬ë¶„ì˜ ì°½ì˜ì„±ì´ ë¹›ë‚˜ê³  ìˆì–´ìš”.")
        
        return "\n".join(feedback) 